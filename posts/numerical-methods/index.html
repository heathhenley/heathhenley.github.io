<!doctype html><html lang=en-us prefix="og: http://ogp.me/ns#"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Notes: Gradient Descent, Newton-Raphson, Lagrange Multipliers</title><meta property="og:title" content="Notes: Gradient Descent, Newton-Raphson, Lagrange Multipliers"><meta name=twitter:title content="Notes: Gradient Descent, Newton-Raphson, Lagrange Multipliers"><meta name=description content="A quick 'non-mathematical' introduction to the most basic forms of gradient descent and Newton-Raphson methods to solve optimization problems involving functions of more than one variable. We also look at the Lagrange Multiplier method to solve optimization problems subject to constraints (and what the resulting system of nonlinear equations looks like, eg what we could apply Newton-Raphson to, etc)."><meta property="og:description" content="A quick 'non-mathematical' introduction to the most basic forms of gradient descent and Newton-Raphson methods to solve optimization problems involving functions of more than one variable. We also look at the Lagrange Multiplier method to solve optimization problems subject to constraints (and what the resulting system of nonlinear equations looks like, eg what we could apply Newton-Raphson to, etc)."><meta name=twitter:description content="A quick 'non-mathematical' introduction to the most basic forms of gradient descent and Newton-Raphson methods to solve optimization problems involving functions of more than one variable. We also …"><meta name=author content="Heath Henley"><meta property="og:site_name" content="Blogging by Heath™"><meta property="og:url" content="https://heathhenley.dev/posts/numerical-methods/"><meta property="og:image" content="https://heathhenley.dev/optimize/gx_constrained.png"><meta name=twitter:image content="https://heathhenley.dev/optimize/gx_constrained.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@Heath_Henley"><meta name=twitter:creator content="@Heath_Henley"><meta property="og:type" content="article"><meta name=generator content="Hugo 0.118.2"><script async src="https://www.googletagmanager.com/gtag/js?id=G-LHHPTPJRGL"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LHHPTPJRGL")</script><link rel=stylesheet href=https://heathhenley.dev/css/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/sakura.css/css/sakura.css type=text/css><link rel=stylesheet href=https://heathhenley.dev/css/custom.css><link rel=icon type=image/x-icon href=https://heathhenley.dev/favicon.png><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><script type=text/javascript src=https://heathhenley.dev/js/bundle.js></script></head><body><a href=#main class="skip-link p-screen-reader-text">Skip to content</a><svg xmlns="http://www.w3.org/2000/svg" style="display:none" aria-hidden="true"><symbol id="icon-500px" viewBox="0 0 16 16"><g><path d="M3.953 10.512a5.24 5.24.0 006.996 3.141c.625-.262 1.184-.641 1.666-1.122s.859-1.041 1.122-1.666c.272-.647.412-1.331.412-2.037s-.137-1.394-.412-2.037c-.262-.625-.641-1.184-1.122-1.666s-1.041-.859-1.666-1.122A5.226 5.226.0 008.912 3.59c-.716.0-1.431.144-2.066.413-.509.216-1.372.769-1.875 1.291l-.003.003V.984h7.241c.262-.003.262-.372.262-.491.0-.122.0-.487-.266-.491H4.377a.343.343.0 00-.344.341v6.066c0 .197.244.338.472.384.444.094.544-.047.653-.197l.016-.019c.166-.247.681-.766.688-.772a4.262 4.262.0 013.037-1.25c1.147.0 2.222.444 3.028 1.25a4.245 4.245.0 011.256 3.019 4.236 4.236.0 01-1.25 3.019 4.336 4.336.0 01-3.047 1.25 4.136 4.136.0 01-2.159-.597l.003-3.688c0-.491.213-1.028.572-1.431a2.09 2.09.0 011.588-.716c.594.0 1.15.225 1.566.634.409.406.637.95.637 1.528A2.179 2.179.0 018.887 11.02c-.238.0-.672-.106-.691-.109-.25-.075-.356.272-.391.387-.134.441.069.528.109.541.397.125.659.147 1.003.147a3.173 3.173.0 003.169-3.169c0-1.734-1.422-3.144-3.166-3.144-.856.0-1.659.328-2.263.919-.575.566-.903 1.319-.903 2.069v.019c-.003.094-.003 2.306-.006 3.031l-.003-.003c-.328-.363-.653-.919-.869-1.488-.084-.222-.275-.184-.534-.103-.125.034-.469.141-.391.394zm3.722-.865c0 .106.097.2.156.253l.019.019c.1.097.194.147.281.147a.181.181.0 00.131-.05c.044-.041.537-.544.588-.591l.553.55c.05.056.106.088.172.088.088.0.184-.053.284-.156.238-.244.119-.375.063-.438l-.559-.559.584-.588c.128-.137.016-.284-.097-.397-.162-.162-.322-.206-.422-.112l-.581.581-.588-.588a.16.16.0 00-.113-.047c-.078.0-.172.053-.275.156-.181.181-.219.306-.125.406l.588.584-.584.584c-.053.05-.078.103-.075.156zm1.278-7.931c-.938.0-1.938.191-2.669.506a.207.207.0 00-.134.181.753.753.0 00.069.337c.047.116.166.425.4.334a6.689 6.689.0 012.334-.444 6.35 6.35.0 012.469.497c.622.263 1.206.644 1.844 1.194a.22.22.0 00.147.059c.125.0.244-.122.347-.237.169-.191.287-.35.119-.509a6.858 6.858.0 00-2.1-1.356 7.326 7.326.0 00-2.825-.563zM14.006 13.3c-.113-.113-.209-.178-.294-.203s-.162-.006-.222.053l-.056.056a6.32 6.32.0 01-6.938 1.356 6.336 6.336.0 01-2.013-1.356 6.046 6.046.0 01-1.356-2.012c-.288-.713-.381-1.247-.413-1.422-.003-.016-.006-.028-.006-.037-.041-.206-.231-.222-.503-.178-.112.019-.459.072-.428.319v.006a7.261 7.261.0 002.04 3.994 7.266 7.266.0 0010.288.0l.059-.059c.069-.084.134-.225-.159-.516z"/></g></symbol><symbol id="icon-codepen" viewBox="0 0 16 16"><g><path d="M14.777 5.751l-7-4.667a.5.5.0 00-.555.0l-7 4.667a.501.501.0 00-.223.416v4.667c0 .167.084.323.223.416l7 4.667a.5.5.0 00.554.0l7-4.667a.501.501.0 00.223-.416V6.167a.501.501.0 00-.223-.416zM7.5 10.232 4.901 8.5 7.5 6.768 10.099 8.5 7.5 10.232zM8 5.899V2.434l5.599 3.732L11 7.898l-3-2zm-1 0-3 2-2.599-1.732L7 2.435V5.9zM3.099 8.5 1 9.899V7.101L3.099 8.5zM4 9.101l3 2v3.465l-5.599-3.732L4 9.102zm4 2 3-2 2.599 1.732L8 14.565V11.1zM11.901 8.5 14 7.101v2.798L11.901 8.5z"/></g></symbol><symbol id="icon-dribbble" viewBox="0 0 16 16"><g><path d="M8 16c-4.412.0-8-3.588-8-8s3.587-8 8-8c4.412.0 8 3.587 8 8s-3.588 8-8 8zm6.747-6.906c-.234-.075-2.116-.634-4.256-.291a29.7 29.7.0 011.328 4.872 6.845 6.845.0 002.928-4.581zM10.669 14.3c-.103-.6-.497-2.688-1.456-5.181-.016.006-.031.009-.044.016-3.856 1.344-5.241 4.016-5.362 4.266a6.807 6.807.0 006.863.9zm-7.747-1.722c.156-.266 2.031-3.369 5.553-4.509a7.04 7.04.0 01.269-.081 24.04 24.04.0 00-.553-1.159c-3.409 1.022-6.722.978-7.022.975-.003.069-.003.138-.003.209.0 1.753.666 3.356 1.756 4.566zM1.313 6.609c.306.003 3.122.016 6.319-.831A43.092 43.092.0 005.098 1.825 6.854 6.854.0 001.314 6.609zM6.4 1.366a36.612 36.612.0 012.55 4c2.431-.909 3.459-2.294 3.581-2.469A6.799 6.799.0 006.4 1.366zm6.891 2.325c-.144.194-1.291 1.663-3.816 2.694.159.325.313.656.453.991.05.119.1.234.147.353 2.275-.284 4.534.172 4.759.219A6.816 6.816.0 0013.29 3.692z"/></g></symbol><symbol id="icon-facebook" viewBox="0 0 16 16"><g><path d="M9.5 3H12V0H9.5C7.57.0 6 1.57 6 3.5V5H4v3h2v8h3V8h2.5l.5-3H9V3.5c0-.271.229-.5.5-.5z"/></g></symbol><symbol id="icon-feed" viewBox="0 0 16 16"><g><path d="M2.13 11.733c-1.175.0-2.13.958-2.13 2.126.0 1.174.955 2.122 2.13 2.122a2.126 2.126.0 002.133-2.122A2.133 2.133.0 002.13 11.733zM.002 5.436v3.067c1.997.0 3.874.781 5.288 2.196a7.45 7.45.0 012.192 5.302h3.08c0-5.825-4.739-10.564-10.56-10.564zM.006.0v3.068C7.128 3.068 12.924 8.87 12.924 16H16C16 7.18 8.824.0.006.0z"/></g></symbol><symbol id="icon-flickr" viewBox="0 0 16 16"><g><path d="M0 8.5a3.5 3.5.0 117 0 3.5 3.5.0 01-7 0zm9 0a3.5 3.5.0 117 0 3.5 3.5.0 01-7 0z"/></g></symbol><symbol id="icon-github" viewBox="0 0 16 16"><g><path d="M8 .198A8 8 0 005.471 15.789c.4.074.547-.174.547-.385.0-.191-.008-.821-.011-1.489-2.226.484-2.695-.944-2.695-.944-.364-.925-.888-1.171-.888-1.171-.726-.497.055-.486.055-.486.803.056 1.226.824 1.226.824.714 1.223 1.872.869 2.328.665.072-.517.279-.87.508-1.07-1.777-.202-3.645-.888-3.645-3.954.0-.873.313-1.587.824-2.147-.083-.202-.357-1.015.077-2.117.0.0.672-.215 2.201.82A7.672 7.672.0 018 4.066c.68.003 1.365.092 2.004.269 1.527-1.035 2.198-.82 2.198-.82.435 1.102.162 1.916.079 2.117.513.56.823 1.274.823 2.147.0 3.073-1.872 3.749-3.653 3.947.287.248.543.735.543 1.481.0 1.07-.009 1.932-.009 2.195.0.213.144.462.55.384A8 8 0 008.001.196z"/></g></symbol><symbol id="icon-gitlab" viewBox="0 0 28 28"><g><path d="M1.625 11.031 14 26.89.437 17.046a1.092 1.092.0 01-.391-1.203l1.578-4.813zm7.219.0h10.313L14.001 26.89zM5.75 1.469l3.094 9.562H1.625l3.094-9.562a.548.548.0 011.031.0zm20.625 9.562 1.578 4.813a1.09 1.09.0 01-.391 1.203l-13.563 9.844 12.375-15.859zm0 0h-7.219l3.094-9.562a.548.548.0 011.031.0z"/></g></symbol><symbol id="icon-google-plus" viewBox="0 0 16 16"><g><path d="M5.091 7.147v1.747h2.888c-.116.75-.872 2.197-2.888 2.197-1.737.0-3.156-1.441-3.156-3.216s1.419-3.216 3.156-3.216c.991.0 1.65.422 2.028.784L8.5 4.112c-.888-.828-2.037-1.331-3.409-1.331C2.275 2.784.0 5.059.0 7.875s2.275 5.091 5.091 5.091c2.937.0 4.888-2.066 4.888-4.975.0-.334-.037-.591-.081-.844H5.092zM16 7h-1.5V5.5H13V7h-1.5v1.5H13V10h1.5V8.5H16z"/></g></symbol><symbol id="icon-instagram" viewBox="0 0 22 22"><g><path d="M15.445.0H6.554A6.559 6.559.0 000 6.554v8.891A6.559 6.559.0 006.554 22h8.891a6.56 6.56.0 006.554-6.555V6.554A6.557 6.557.0 0015.445.0zm4.342 15.445a4.343 4.343.0 01-4.342 4.342H6.554a4.341 4.341.0 01-4.341-4.342V6.554a4.34 4.34.0 014.341-4.341h8.891a4.342 4.342.0 014.341 4.341l.001 8.891z"/><path d="M11 5.312A5.693 5.693.0 005.312 11 5.694 5.694.0 0011 16.688 5.694 5.694.0 0016.688 11 5.693 5.693.0 0011 5.312zm0 9.163a3.475 3.475.0 11-.001-6.95 3.475 3.475.0 01.001 6.95zm5.7-10.484a1.363 1.363.0 11-1.364 1.364c0-.752.51-1.364 1.364-1.364z"/></g></symbol><symbol id="icon-linkedin" viewBox="0 0 16 16"><g><path d="M6 6h2.767v1.418h.04C9.192 6.727 10.134 6 11.539 6 14.46 6 15 7.818 15 10.183V15h-2.885v-4.27c0-1.018-.021-2.329-1.5-2.329-1.502.0-1.732 1.109-1.732 2.255V15H6V6zM1 6h3v9H1V6zM4 3.5A1.5 1.5.0 11.999 3.499 1.5 1.5.0 014 3.5z"/></g></symbol><symbol id="icon-mail" viewBox="0 0 22 18"><g><path fill="#000" d="M0 17.225V.776h22v16.447H0v.002zm3.011-1.815h15.978l-5.111-5.115L11 13.179l-2.877-2.883-5.112 5.114zm-1.216-1.275 5.077-5.09L1.795 3.98v10.155zm13.332-5.09 5.079 5.09V3.979l-5.079 5.066zm-4.126 1.588 8.022-8.027-16.045-.001 8.023 8.028z"/></g></symbol><symbol id="icon-medium" viewBox="0 0 24 24"><g><path d="M22.085 4.733 24 2.901V2.5h-6.634l-4.728 11.768L7.259 2.5H.303v.401L2.54 5.594c.218.199.332.49.303.783V16.96c.069.381-.055.773-.323 1.05L0 21.064v.396h7.145v-.401l-2.52-3.049a1.244 1.244.0 01-.347-1.05V7.806l6.272 13.659h.729l5.393-13.659v10.881c0 .287.0.346-.188.534l-1.94 1.877v.402h9.412v-.401l-1.87-1.831a.556.556.0 01-.214-.534V5.267a.554.554.0 01.213-.534z"/></g></symbol><symbol id="icon-npm" viewBox="0 0 16 16"><g><path d="M0 0v16h16V0H0zm13 13h-2V5H8v8H3V3h10v10z"/></g></symbol><symbol id="icon-pinterest" viewBox="0 0 16 16"><g><path d="M8 1.069A6.93 6.93.0 005.475 14.453c-.059-.547-.116-1.391.025-1.988.125-.541.813-3.444.813-3.444s-.206-.416-.206-1.028c0-.963.559-1.684 1.253-1.684.591.0.878.444.878.975.0.594-.378 1.484-.575 2.306-.166.691.344 1.253 1.025 1.253 1.231.0 2.178-1.3 2.178-3.175.0-1.659-1.194-2.819-2.894-2.819-1.972.0-3.128 1.478-3.128 3.009.0.597.228 1.234.516 1.581.056.069.066.128.047.2a95.89 95.89.0 01-.194.787c-.031.128-.1.153-.231.094-.866-.403-1.406-1.669-1.406-2.684.0-2.188 1.587-4.194 4.578-4.194 2.403.0 4.272 1.712 4.272 4.003.0 2.388-1.506 4.313-3.597 4.313-.703.0-1.362-.366-1.588-.797.0.0-.347 1.322-.431 1.647-.156.603-.578 1.356-.862 1.816a6.93 6.93.0 008.984-6.622A6.931 6.931.0 008.001 1.068z"/></g></symbol><symbol id="icon-search" viewBox="0 0 16 16"><g><path d="M15.504 13.616l-3.79-3.223c-.392-.353-.811-.514-1.149-.499a6 6 0 10-.672.672c-.016.338.146.757.499 1.149l3.223 3.79c.552.613 1.453.665 2.003.115s.498-1.452-.115-2.003zM6 10a4 4 0 110-8 4 4 0 010 8z"/></g></symbol><symbol id="icon-strava" viewBox="0 0 24 24"><g><path d="M15.387 17.944l-2.089-4.116h-3.065L15.387 24l5.15-10.172h-3.066m-7.008-5.599 2.836 5.598h4.172L10.463.0l-7 13.828h4.169"/></g></symbol><symbol id="icon-threads" viewBox="0 0 100 100"><g><path d="M48.793 51.383c-2.204.298-3.997 1.235-5.035 2.644-.85 1.148-1.145 2.546-.88 4.139.25 1.484.71 4.252 7.99 4.252 6.972.0 8.895-7.01 9.426-10.856-1.853-.369-3.868-.558-6.019-.558-1.75.0-3.58.124-5.482.379z"/><path d="M97.432 20.541C95.764 11.247 88.7 4.188 79.437 2.557c-19.5-3.429-39.563-3.39-58.888.003-9.257 1.663-16.316 8.722-17.981 17.994A171.192 171.192.0 000 50.077c0 9.779.864 19.66 2.568 29.358 1.63 9.264 8.688 16.328 17.998 18.002A171.463 171.463.0 0050.083 1e2c9.772.0 19.647-.861 29.354-2.563 9.442-1.663 16.338-8.56 18-18.002A170.58 170.58.0 001e2 50.077c0-9.881-.861-19.812-2.568-29.536zM79.854 40.407c-1.771.59-3.678-.439-4.23-2.224-3.987-12.831-11.436-18.065-25.704-18.065-17.323.0-25.392 10.02-25.392 31.53.0 18.16 8.911 27.922 25.771 28.226 7.15.249 13.57-2.043 17.633-6.02 2.773-2.713 4.241-6.045 4.241-9.626.0-3.776-1.284-6.815-3.819-9.036a12.92 12.92.0 00-1.609-1.198c-1.771 9.443-7.692 15.186-15.877 15.186-10.75.0-13.905-5.385-14.658-9.898-.572-3.424.16-6.631 2.107-9.27 2.134-2.893 5.536-4.789 9.583-5.33 4.382-.586 8.477-.575 12.155-.038-.606-2.612-1.814-4.746-3.51-6.017-3.797-2.792-10.698-2.527-14.485 2.354a3.372 3.372.0 01-4.743.602 3.381 3.381.0 01-.603-4.743c6.256-8.073 17.377-8.4 23.861-3.644 3.825 2.872 6.154 7.699 6.598 13.414 2.129.91 4.02 2.075 5.64 3.494 4.002 3.511 6.12 8.392 6.12 14.124.0 5.363-2.226 10.5-6.272 14.46-5.19 5.076-13.045 7.958-21.658 7.958-.281.0-.557-.006-.834-.011-20.587-.368-32.401-13.121-32.401-34.987.0-25.408 10.817-38.29 32.152-38.29 17.334.0 27.253 7.037 32.16 22.82a3.38 3.38.0 01-2.226 4.229z"/></g></symbol><symbol id="icon-tumblr" viewBox="0 0 16 16"><g><path d="M9.001 7v3.659c0 .928-.012 1.463.086 1.727.098.262.342.534.609.691.354.212.758.318 1.214.318.81.0 1.289-.107 2.09-.633v2.405a9.089 9.089.0 01-1.833.639A7.93 7.93.0 019.369 16a4.9 4.9.0 01-1.725-.276 4.195 4.195.0 01-1.438-.79c-.398-.343-.672-.706-.826-1.091s-.23-.944-.23-1.676V6.556H3.003V4.29c.628-.204 1.331-.497 1.778-.877a4.386 4.386.0 001.08-1.374C6.133 1.505 6.32.825 6.422.0h2.579v4H13v3H9.001z"/></g></symbol><symbol id="icon-twitter" viewBox="0 0 16 16"><g><path d="M16 3.538a6.461 6.461.0 01-1.884.516 3.301 3.301.0 001.444-1.816 6.607 6.607.0 01-2.084.797 3.28 3.28.0 00-2.397-1.034A3.28 3.28.0 007.882 6.029 9.321 9.321.0 011.116 2.598a3.284 3.284.0 001.015 4.381A3.301 3.301.0 01.643 6.57v.041A3.283 3.283.0 003.277 9.83a3.291 3.291.0 01-1.485.057 3.293 3.293.0 003.066 2.281 6.586 6.586.0 01-4.862 1.359 9.286 9.286.0 005.034 1.475c6.037.0 9.341-5.003 9.341-9.341.0-.144-.003-.284-.009-.425a6.59 6.59.0 001.637-1.697z"/></g></symbol><symbol id="icon-vimeo" viewBox="0 0 16 16"><g><path d="M15.994 4.281c-.072 1.556-1.159 3.691-3.263 6.397-2.175 2.825-4.016 4.241-5.522 4.241-.931.0-1.722-.859-2.366-2.581-.431-1.578-.859-3.156-1.291-4.734-.478-1.722-.991-2.581-1.541-2.581-.119.0-.538.253-1.256.753l-.753-.969c.791-.694 1.569-1.388 2.334-2.081 1.053-.909 1.844-1.387 2.372-1.438 1.244-.119 2.013.731 2.3 2.553.309 1.966.525 3.188.647 3.666.359 1.631.753 2.447 1.184 2.447.334.0.838-.528 1.509-1.588.669-1.056 1.028-1.862 1.078-2.416.097-.912-.262-1.372-1.078-1.372a2.98 2.98.0 00-1.184.263c.787-2.575 2.287-3.825 4.506-3.753 1.641.044 2.416 1.109 2.322 3.194z"/></g></symbol><symbol id="icon-wordpress" viewBox="0 0 16 16"><g><path d="M2 8c0 2.313 1.38 4.312 3.382 5.259L2.52 5.622A5.693 5.693.0 002 8zm10.05-.295c0-.722-.266-1.222-.495-1.612-.304-.482-.589-.889-.589-1.371.0-.537.418-1.037 1.008-1.037.027.0.052.003.078.005A6.064 6.064.0 008 2.156 6.036 6.036.0 002.987 4.79c.141.004.274.007.386.007.627.0 1.599-.074 1.599-.074.323-.018.361.444.038.482.0.0-.325.037-.687.055l2.185 6.33 1.313-3.835-.935-2.495a12.304 12.304.0 01-.629-.055c-.323-.019-.285-.5.038-.482.0.0.991.074 1.58.074.627.0 1.599-.074 1.599-.074.323-.018.362.444.038.482.0.0-.326.037-.687.055l2.168 6.282.599-1.947c.259-.809.457-1.389.457-1.889zm-3.945.806-1.8 5.095a6.148 6.148.0 003.687-.093.52.52.0 01-.043-.081L8.105 8.511zm5.16-3.315c.026.186.04.386.04.601.0.593-.114 1.259-.456 2.093l-1.833 5.16c1.784-1.013 2.983-2.895 2.983-5.051a5.697 5.697.0 00-.735-2.803zM8 0a8 8 0 100 16A8 8 0 008 0zm0 15A7 7 0 118 1a7 7 0 010 14z"/></g></symbol><symbol id="icon-youtube" viewBox="0 0 16 16"><g><path d="M15.841 4.8s-.156-1.103-.637-1.587c-.609-.637-1.291-.641-1.603-.678-2.237-.163-5.597-.163-5.597-.163h-.006s-3.359.0-5.597.163c-.313.038-.994.041-1.603.678C.317 3.697.164 4.8.164 4.8S.005 6.094.005 7.391v1.213c0 1.294.159 2.591.159 2.591s.156 1.103.634 1.588c.609.637 1.409.616 1.766.684 1.281.122 5.441.159 5.441.159s3.363-.006 5.6-.166c.313-.037.994-.041 1.603-.678.481-.484.637-1.588.637-1.588s.159-1.294.159-2.591V7.39c-.003-1.294-.162-2.591-.162-2.591zm-9.494 5.275V5.578l4.322 2.256-4.322 2.241z"/></g></symbol><symbol id="icon-mastodon" viewBox="0 0 16 16"><g><path d="M11.19 12.195c2.016-.24 3.77-1.475 3.99-2.603.348-1.778.32-4.339.32-4.339.0-3.47-2.286-4.488-2.286-4.488C12.062.238 10.083.017 8.027.0h-.05C5.92.017 3.942.238 2.79.765c0 0-2.285 1.017-2.285 4.488l-.002.662c-.004.64-.007 1.35.011 2.091.083 3.394.626 6.74 3.78 7.57 1.454.383 2.703.463 3.709.408 1.823-.1 2.847-.647 2.847-.647l-.06-1.317s-1.303.41-2.767.36c-1.45-.05-2.98-.156-3.215-1.928a4 4 0 01-.033-.496s1.424.346 3.228.428c1.103.05 2.137-.064 3.188-.189zm1.613-2.47H11.13v-4.08c0-.859-.364-1.295-1.091-1.295-.804.0-1.207.517-1.207 1.541v2.233H7.168V5.89c0-1.024-.403-1.541-1.207-1.541-.727.0-1.091.436-1.091 1.296v4.079H3.197V5.522q0-1.288.66-2.046c.456-.505 1.052-.764 1.793-.764.856.0 1.504.328 1.933.983L8 4.39l.417-.695c.429-.655 1.077-.983 1.934-.983.74.0 1.336.259 1.791.764q.662.757.661 2.046z"/></g></symbol><symbol id="icon-bluesky" viewBox="0 0 256 226"><path d="M55.491 15.172c29.35 22.035 60.917 66.712 72.509 90.686 11.592-23.974 43.159-68.651 72.509-90.686C221.686-.727 256-13.028 256 26.116c0 7.818-4.482 65.674-7.111 75.068-9.138 32.654-42.436 40.983-72.057 35.942 51.775 8.812 64.946 38 36.501 67.187-54.021 55.433-77.644-13.908-83.696-31.676-1.11-3.257-1.63-4.78-1.637-3.485-.008-1.296-.527.228-1.637 3.485-6.052 17.768-29.675 87.11-83.696 31.676-28.445-29.187-15.274-58.375 36.5-67.187-29.62 5.041-62.918-3.288-72.056-35.942C4.482 91.79.0 33.934.0 26.116.0-13.028 34.314-.727 55.491 15.172"/></symbol></svg><header class=l-header><p class="c-title p-title"><a href=https://heathhenley.dev/ class=p-title__link>Blogging by Heath™</a></p><p class=p-subtitle>A mostly technical blog and collection of my notes and thoughts</p></header><main id=main class=l-main><article class=p-article><header><h1>Notes: Gradient Descent, Newton-Raphson, Lagrange Multipliers</h1><div><div class=c-meta>Posted on
<time datetime=2024-05-26T00:15:12-04:00>May 26, 2024</time>
|
3202 words
|
~16mins</div></div><a href=https://heathhenley.dev/tags/python class=c-tag>python</a>
<a href=https://heathhenley.dev/tags/numerical class=c-tag>numerical</a>
<a href=https://heathhenley.dev/tags/methods class=c-tag>methods</a>
<a href=https://heathhenley.dev/tags/optimization class=c-tag>optimization</a></div></header><section id=js-article class=p-article__body><p><em>TL;DR:</em> A quick &ldquo;non-mathematical&rdquo; introduction to the most basic forms of
gradient descent and Newton-Raphson methods to solve optimization problems
involving functions of more than one variable. We also look at the Lagrange
Multiplier method to solve optimization problems subject to constraints (and
what the resulting system of nonlinear equations looks like, eg what we could
apply Newton-Raphson to, etc).</p><h2 id=introduction>Introduction</h2><p>Optimization problems are everywhere in engineering and science. If you can
model your problem in a way that can write down some function that should be
minimized or maximized (the objective function) to get the solution you want,
even in cases where there is no analytical solution (most real cases), you can
often obtain a numerical solution.</p><p>You can find critical points of a function (minima, maxima, and saddle points)
by differentiating the function and setting the derivatives to zero. When you
have a function of just one variable, this is pretty straightforward and you end
up with a single equation to solve. When you have a function of multiple
variables, you end up with a system of equations to solve. For example, if you
have a function $F(x, y)$ and you want to find the critical points, you need to
solve the system of equations:</p><p>$$
\partial F/\partial x = 0 \quad \text{and} \quad \partial F/\partial y = 0
$$</p><p>This can be a system of nonlinear equations, depending on the function
$F(x, y)$ of course.</p><p>To make this more concrete, let&rsquo;s take a simple function:
$$
G(X) = \sum_i x_i \ln(x_i)
$$
We want to find the values of $x_i$ that minimize $G(X)$. This is nice and
simple so that we can solve it analytically - we can take the derivative of $G$
and set them equal to zero, we end up with an equation given by the
derivative with respect to $x_i$ for each $x_i$ we have:</p><p>$$
\frac{\partial G}{\partial x_i} = \ln(x_i) + 1 = 0
$$</p><p>This gives us the solution $x_i = 1/e \approx 0.368$ for all $i$. So we know
that there is a critical point at $x_i = 1/e$ for all $i$ - it turns out that
this is a minimum because we chose a nice convex function (more checks required
when you have a more complex function, of course, hold please).</p><p>To check this, we can plot the function $G(X)$ for two variables $x_1$ and $x_2$
and see what it looks like.</p><p><img src=/optimize/gx.png alt="plot of g(X) in two variable with min marked"></p><p>The red dot is at the minimum at $x_1 = x_2 = 1/e$. Ok cool, so this was is a
easy case to work with. Let&rsquo;s use it to look at some other methods, that can
be used here, but also in more general cases for either minimizing or solving
a system of equations numerically. ..</p><h2 id=gradient-descent>Gradient Descent</h2><p>The gradient descent or steepest descent method is a simple method we can use to
find the minimum of a function or solve a system of equations (if we minimize
the square of the residual in the system).
The idea is to start at some guess
and always take steps the direction that reduces the value
of the objective function the most. There&rsquo;s a million posts, blogs and papers
on this, so I&rsquo;m not going to belabor the point. We&rsquo;re going to compute the
gradient of the function and take steps in the direction of the negative
gradient. For the function $G(X)$ above, we can compute the gradient as:</p><p>$$
\nabla G = \left[ \frac{\partial G}{\partial x_1}, \frac{\partial G}{\partial x_2} \right] = \left[ \ln(x_1) + 1, \ln(x_2) + 1 \right]
$$
We can then take steps in the direction of the negative gradient. To avoid
overshooting or taking too large of a step, we can multiply the gradient by a
small number called the step size or learning rate. This is a &lsquo;hyperparameter&rsquo;
that you can tune to make the algorithm converge faster or slower. The update
looks like this:</p><p>$$
X_{n+1} = X_n - \alpha \nabla G
$$
where $\alpha$ is the learning rate. We can plot the steps that the algorithm
takes to converge to the minimum:</p><p><img src=/optimize/gx_gd.png alt="plot of g(X) in two variable with min marked"></p><p>Which is pretty cool! If you&rsquo;re interested, this is what it looks like in code:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dg</span>(x):
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>log(x) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>step_size <span style=color:#f92672>=</span> learning_rate <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.1</span> <span style=color:#75715e># hyperparameter</span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.2</span>]) <span style=color:#75715e># initial guess</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># gradient descent</span>
</span></span><span style=display:flex><span>residual <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> residual <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1e-8</span>:
</span></span><span style=display:flex><span>  residual <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(dg(x)<span style=color:#f92672>.</span>T, dg(x))
</span></span><span style=display:flex><span>  x <span style=color:#f92672>=</span> x <span style=color:#f92672>-</span> step_size <span style=color:#f92672>*</span> dg(x)
</span></span></code></pre></div><p>The good thing about this method is that it&rsquo;s easy to implement and we&rsquo;re always
moving in the direction of &lsquo;steepest descent&rsquo; - the direction that reduces the
value of the function the most. The bad thing is that it can be slow to
converge, especially if the function is &lsquo;flat&rsquo; near the minimum. You can see in
that there are a lot of steps taken near the minimum, which is inefficient.</p><p>This algorithm converges linearly, which means that the error decreases by a
constant factor at each iteration. There&rsquo;s another popular method called the
Newton-Raphson method which converges quadratically, so that the error
decreases much faster at each iteration.</p><p>Gradient descent finds a local minimum of the function we&rsquo;re interested in.
Newton-Raphson is a root finding method be can be used to find critical points,
including minima, if we take the derivatives of the function we&rsquo;re interested
in and set them to zero, and apply Newton Raphson to the resulting system of
equations.</p><h2 id=newton-raphson>Newton-Raphson</h2><p>To use the Newton-Raphson method to minimize our test function $G(X)$, we need
to write it as a system of equations. We can do this by taking the partial
derivatives of $G$ with respect to each $x_i$ and setting them equal to zero, so
that we have an equation for each $x_i$:
$$
\frac{\partial G}{\partial x_i} = \ln(x_i) + 1 = 0
$$
Our new system, $F(X)$ is the system of equations above. For only two
variables, we&rsquo;ll have:</p><p>$$
F(X) =
\begin{bmatrix}
\ln(x_1) + 1 \\ \ln(x_2) + 1
\end{bmatrix} = 0
$$</p><p>An approximate &lsquo;hand-wavy&rsquo; way to see how we can continue to think of a linear
approximation to the function near the minimum, so something like a truncated
Taylor series:</p><p>$$
F(X) \approx F(X_0) + DF(X_0) \cdot (X - X_0)
$$</p><p>Where $DF(X_0)$ is the &ldquo;Jacobian&rdquo; of $F$ at $X_0$, or a matrix of where the
rows correspond to the equations in $F$ and the columns correspond to the
partial derivatives of each equation with respect to each variable. For example:</p><p>$$
DF =
\begin{bmatrix}
\frac{\partial F_1}{\partial x_1} & \dots & \frac{\partial F_1}{\partial x_n} \\
\vdots & \ddots & \ \vdots \\
\frac{\partial F_m}{\partial x_1} & \dots & \frac{\partial F_m}{\partial x_n} \\
\end{bmatrix}
$$</p><p>or in our specific using our example with two variables, the Jacobian is:</p><p>$$
DF =
\begin{bmatrix}
\frac{1}{x_1} & 0 \\
0 & \frac{1}{x_2}
\end{bmatrix}
$$</p><p>We can take that linear approximation and rearrange it to solve for $X$:</p><p>$$
X = X_0 - DF(X_0)^{-1} \cdot F(X_0)
$$</p><p>Which gives the update rule that we need for Newton&rsquo;s method. We can also write
this a different way, as a linear system of equations, which is the way that it
is usually implemented (to avoid inverting the Jacobian):</p><p>$$
DF(X_0) \cdot \Delta X = -F(X_0)
$$</p><p>Which we can solve for $\Delta X$ and update $X$ as:</p><p>$$
X = X_0 + \Delta X
$$</p><p>This is what it looks like in code:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>jacobi</span>(x):
</span></span><span style=display:flex><span>  j <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((x<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], x<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]))
</span></span><span style=display:flex><span>  np<span style=color:#f92672>.</span>fill_diagonal(j, <span style=color:#ae81ff>1</span><span style=color:#f92672>/</span>x)
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> j
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># newton raphson</span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(x0)
</span></span><span style=display:flex><span>residual <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> residual <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1e-8</span>:
</span></span><span style=display:flex><span>  residual <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(dg(x)<span style=color:#f92672>.</span>T, dg(x))
</span></span><span style=display:flex><span>  dx <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linalg<span style=color:#f92672>.</span>solve(jacobi(x), <span style=color:#f92672>-</span>dg(x))
</span></span><span style=display:flex><span>  x <span style=color:#f92672>=</span> x <span style=color:#f92672>+</span> dx
</span></span></code></pre></div><p>And with our test function, here&rsquo;s the steps look like:</p><p><img src=/optimize/gx_gd_nr.png alt="plot of g(X) in two variable with min marked"></p><p>So it converges fast on it&rsquo;s own and we don&rsquo;t need to tune the learning rate as
we did with gradient descent (it diverges or bounces around if the step size /
learning rate is too high). However, we need to compute the Jacobian here, which
is really the second derivatives of the original function we were working (it&rsquo;s
the Hessian wrt our test function $G(X)$), which can more difficult or less
efficient to compute. Still, Newton&rsquo;s method usually converges quadratically, or
it does when it&rsquo;s &ldquo;sufficiently close&rdquo; to the minimum and some other criteria
are met.</p><p>These methods can be combined to get the benefits of each. For example:
trying to use Newton&rsquo;s method, but falling back to gradient descent if the
the function at the new point is much different than what we
expected.</p><p>There are a lot algorithms developed to improve the Newton-Raphson method,
especially far from the solution (Trust region methods) and to avoid direct
computation of the Hessian (the Jacobian in our example above) (Quasi-Newton
Methods).</p><p>Of course they&rsquo;re all implemented, in packages like <a href=https://docs.scipy.org/doc/scipy/reference/optimize.html><code>scipy.optimize</code></a>, Matlab,
etc, so you&rsquo;ll never have to implement them yourself. But it&rsquo;s interesting to
understand the basics about them.</p><p>So far, we&rsquo;re only looking at unconstrained optimization, but there are a lot of
cases where we have some constraints on the variables that we need to satisfy.
For example, maybe in our test function $G(X)$, we need to find the minimum
in the function where all $x_i$ need to add up to 1. How do we handle that?</p><h2 id=constrained-optimization>Constrained Optimization</h2><p>The methods that I&rsquo;m familiar with for handling optimization problems with
constraints basically involve transforming the problem into an unconstrained
problem and then solving it the same way we did above. The Lagrange Multiplier
method is one way to do this.</p><p>We can handle optimization subject to some equality constraints using
the <a href=https://en.wikipedia.org/wiki/Lagrange_multiplier>Lagrange Multiplier</a> method. The idea is to take the function we want to
optimize, in our case $G(X)$, and add each constraint, multiplied by a new
variable, called the Lagrange Multiplier, $\lambda$. We then minimize this new
function, which is called the Lagrangian, with respect to all the variables
(the original variables $X$ and the Lagrange Multiplier(s) $\lambda$), instead
of minimizing just the original function. So for example, we want to minimize:</p><p>$$
G(X) \quad \text{subject to} \quad \sum_i x_i = 1
$$</p><p>So we write the Lagrangian as:</p><p>$$
L(X, \lambda) = G(X) + \lambda \left( \sum_i x_i - 1 \right)
$$
If we had more constraints, we would add them to the Lagrangian in the same way,
each with a new Lagrange Multiplier. Then minimize the Lagrangian with respect
to all the variables by taking the partial derivatives with respect to each one
and setting them to zero. This gives us a system of equations to solve, which
we can do using either of the methods we introduced above, or in some cases we
can solve it analytically (like our toy problem above with $G(X)$). It does take
a little extra work if we want to apply gradient descent, because the point that
we&rsquo;re looking is not a local minimum of the Lagrangian, but a saddle point. I
don&rsquo;t understand why it works, but you can apply gradient descent to the &lsquo;x&rsquo;
values, and gradient ascent to the Lagrange Multiplier(s) and it will become
stable and converge to the minimum (example below, after introducing the
Lagrangian for this specific example). This is presented in this <a href=https://papers.nips.cc/paper/1987/hash/a87ff679a2f3e71d9181a67b7542122c-Abstract.html>paper</a>.</p><p>For two variables, we we want to minimize $G(X)$ subject to the constraint that
$x_1 + x_2 = 1$, so we want to find the minimum of $G(X)$ along the red line in
the plot below:</p><p><img src=/optimize/gx_constrained.png alt="plot of g(X) in two variable with min marked"></p><p>To apply the method of Lagrange Multipliers, we write the Lagrangian as:</p><p>$$
L(X, \lambda) = x_1\ln(x_1) + x_2\ln(x_2) + \lambda \left( x_1 + x_2 - 1 \right)
$$
And then take the partial derivatives with respect to each variable and the
Lagrange Multiplier and set them to zero. This gives us a system of equations:
$$
\begin{align*}
\frac{\partial L}{\partial x_1} &= \ln(x_1) + 1 + \lambda = 0 \\
\frac{\partial L}{\partial x_2} &= \ln(x_2) + 1 + \lambda = 0 \\
\frac{\partial L}{\partial \lambda} &= x_1 + x_2 - 1 = 0
\end{align*}
$$
This case is pretty simple to work out analytically, if we wanted to get more
practice, we could use the methods we introduced above to solve it numerically
to make sure we get the same answer.</p><p>For this case:</p><p>$$
x_1 = e^{\lambda - 1}\\
x_2 = e^{\lambda - 1}\\
2e^{\lambda - 1} = 1 \implies \lambda = \ln(1/2) + 1 \implies x_1 = x_2 = 1/2
$$</p><p>This new minimum is marked by the black triangle in the plot above.</p><p>We can actually show that in general, the solution for the minimum of $G(X)$
with any number of variables $n$ subject to the constraint that they all add up
to 1 is $x_i = 1/n$ for all $i$</p><p>We can&rsquo;t apply un modified gradient descent directly because the constrained minimum is
not a local minimum of the Lagrangian, but a saddle point. If we wanted to use
gradient descent we could run it on the square of the gradient of the Lagrangian
instead of the Lagrangian itself, which would give us the minimum.</p><p>There is also a simpler the trick mentioned above and presented in this <a href=https://papers.nips.cc/paper/1987/hash/a87ff679a2f3e71d9181a67b7542122c-Abstract.html>paper</a>
that we can apply here. It&rsquo;s essentially the same thing we would do to apply
gradient descent to the Lagrangian, but the Lagrange multiplier(s) are updated
with gradient <strong>ascent</strong> instead of descent, eg we just add instead of
subtract.</p><p>For this problem it looks like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dgc</span>(x):
</span></span><span style=display:flex><span>  d <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(x<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>  d[:<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>log(x[:<span style=color:#ae81ff>2</span>]) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> x[<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>  d[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> sum(x[:<span style=color:#ae81ff>2</span>]) <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># starting guess</span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.2</span>, <span style=color:#ae81ff>0.0</span>])
</span></span><span style=display:flex><span>step_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># everything is descent, except last variable </span>
</span></span><span style=display:flex><span>dir <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1.0</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>ones(x<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>dir[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>residual <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> residual <span style=color:#f92672>&gt;</span> eps:
</span></span><span style=display:flex><span>  residual <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(dgc(x)<span style=color:#f92672>.</span>T, dgc(x))
</span></span><span style=display:flex><span>  x <span style=color:#f92672>=</span> x <span style=color:#f92672>+</span> dir <span style=color:#f92672>*</span> step_size <span style=color:#f92672>*</span> dgc(x)
</span></span><span style=display:flex><span>print(x) <span style=color:#75715e># [0.5, 0.5, -0.3069]</span>
</span></span></code></pre></div><p>Ok, so that&rsquo;s a quick overview of the simplest versions in more than one
variable of (1) two of the iterative methods that can be applied to
optimization problems (gradient descent &ndash;> local min, Newton-Raphson &ndash;>
find zeros, so it can be used to find critical points), and (2) how to
formulate an optimization problem subject to constraints using the method of
Lagrange Multipliers.</p><p>Here&rsquo;s another example!</p><h2 id=example-water-gas-shift-reaction>Example: Water-Gas Shift Reaction</h2><p>The water-gas shift reaction is an important reaction in many industrial
processes, including the production of hydrogen. It&rsquo;s also convenient because
it&rsquo;s very simple and we can use it to test / illustrate the methods we&rsquo;re
talking about here.</p><p>Let&rsquo;s say we want to compute the equilibrium concentrations of the species in
the water-gas shift reaction, under some conditions and initial concentrations
of water and carbon monoxide.</p><p>The reaction is:
$$
CO + H_2O \rightleftharpoons CO_2 + H_2
$$</p><p>You&rsquo;ll have to take my word for it because it&rsquo;s a little out of scope for this
post, but the reaction proceeds until the Gibbs free energy of the system is
minimized. The Gibbs free energy in this system is given by (under some
assumptions - gas phase reaction, ideal gas behavior):</p><p>$$
\frac{nG}{RT} = \sum_i n_i (\frac{G_i^*}{RT} + \ln(\frac{n_iP}{nP^0}))
$$</p><p>where $n_i$ is the number of moles of species $i$, $G_i^*$ is the Gibbs free
energy of formation of species $i$, (adjusted to temperature of interest - out
of scope, a little tedious but straightforward), $P$ is the total pressure, and
$P^0$ is the standard pressure (1 bar usually). So in terms of the actual
minimization exercise, we only care about the mole numbers, the rest are
constants.</p><p>Here, we do have a constraint, that the total number of moles of all elemental
species is constant - eg we need to do a mass balance on each of the elements
in the system. Then we can use the method of Lagrange Multipliers to write the
Lagrangian:
$$
L = \sum_i^{nc} n_i (\frac{G_i^*}{RT} + \ln(\frac{n_iP}{nP^0})) + \sum_i^{nc} \sum_j^{ne}\lambda_j (a_{ij}n_i - n_j^0)
$$
Where the $\lambda_j$ are the Lagrange Multipliers for each element balance,
and $a_{ij}$ is the stoichiometric coefficient of the element $j$ in species $i$.</p><p>If we differentiate the the Lagrangian with respect to each species mole number
we end up with seven equations to solve, for the seven variables: the mole
numbers of the species in the system, and the Lagrange Multiplier for each
element balance constraint.</p><p>Our system of equations is:</p><p>$$
\begin{align*}
\frac{\partial L}{\partial n_{i}} = \frac{G_i^<em>}{RT} + \ln(\frac{n_iP}{nP^0}) + \sum_j^{ne}\lambda_j a_{ij} = 0 \quad \text{for} \quad i = 1, \dots, nc \\
\frac{\partial L}{\partial \lambda_{j}} = \sum_i^{nc} a_{ij}n_i - n_j^0 = 0 \quad \text{for} \quad j = 1, \dots, ne
\end{align</em>}
$$</p><p>This is a system of nonlinear equations that we could solve using the methods
we introduced above. Those are little more involved in this case, so lets see
how we can lean on the packages like <code>scipy.optimize</code> to do the hard work for
us, given that we now have a rough idea of how they work, at least on a high
level.</p><p>The full code for this example is available as a <a href=https://gist.github.com/heathhenley/98d7e8871de0738713b41f651ed9ec6e>gist</a>, but this is the main part:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>lagrange</span>(x):
</span></span><span style=display:flex><span>  <span style=color:#75715e># Returns the system of equations we got by differentiating the</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Lagranian and setting all the partial derivatives to zero</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># This uses &#39;lagrange mulipliers&#39; to enforce the mass balance</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># constraints, but not to enforce the ni &gt; 0 constraint, we could</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># use homotopy for that (maybe another post or continuation)</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>  n <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sum(x[:<span style=color:#ae81ff>4</span>]) <span style=color:#75715e># total moles</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># these are the partial derivatives of (nG/RT) wrt each species</span>
</span></span><span style=display:flex><span>  g <span style=color:#f92672>=</span> gf <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>log(x[:<span style=color:#ae81ff>4</span>]<span style=color:#f92672>/</span>n) <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>log(p) <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>matmul(x[<span style=color:#ae81ff>4</span>:], aij)
</span></span><span style=display:flex><span>  <span style=color:#75715e># these are the constraints from element balance (the partial</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># derivatives wrt to the lagrange multipiers end up just</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># being the constaints)</span>
</span></span><span style=display:flex><span>  constraints <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>matmul(aij, x[:<span style=color:#ae81ff>4</span>]) <span style=color:#f92672>-</span> n_element_tot
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>concatenate((g, constraints))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>jac</span>(x):
</span></span><span style=display:flex><span>  <span style=color:#75715e># for scipy minimize if we want</span>
</span></span><span style=display:flex><span>  n <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sum(x[:<span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> gf <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>log(x[:<span style=color:#ae81ff>4</span>]<span style=color:#f92672>/</span>n) <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>log(p)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># this is a guess of the solution</span>
</span></span><span style=display:flex><span><span style=color:#75715e># n is [nco, nco2, nh2o, nh2, lc, lh, lo]</span>
</span></span><span style=display:flex><span>n0 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>1.0</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Solve the lagrange problem lagrange((n, l)) = 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   this will tell us if we formulated correctly:</span>
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> scipy<span style=color:#f92672>.</span>optimize<span style=color:#f92672>.</span>fsolve(lagrange, n0)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;LM scipy fsolve: &#34;</span>, res[:<span style=color:#ae81ff>4</span>]<span style=color:#f92672>/</span>sum(res[:<span style=color:#ae81ff>4</span>]))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;  ni:&#34;</span>, res[:<span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;  lambda:&#34;</span>, res[<span style=color:#ae81ff>4</span>:])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Turns out, we don&#39;t actually need to build the constraints into</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the function we pass to scipy.optimize, we can just pass them in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as constraints and scipy will handle it for us. We can also pass</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the jacobian if we want, if we don&#39;t, it will use numerical</span>
</span></span><span style=display:flex><span><span style=color:#75715e># derivatives.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using built in minimization with constraints</span>
</span></span><span style=display:flex><span>cons <span style=color:#f92672>=</span> ({
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;eq&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;fun&#39;</span>: <span style=color:#66d9ef>lambda</span> x: np<span style=color:#f92672>.</span>matmul(aij, x) <span style=color:#f92672>-</span> n_element_tot
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> scipy<span style=color:#f92672>.</span>optimize<span style=color:#f92672>.</span>minimize(
</span></span><span style=display:flex><span>  gibbs, n0[:<span style=color:#ae81ff>4</span>], constraints<span style=color:#f92672>=</span>cons, jac<span style=color:#f92672>=</span>jac)
</span></span><span style=display:flex><span>print(
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Minimize (constained) our derivatives:&#34;</span>,
</span></span><span style=display:flex><span>  res<span style=color:#f92672>.</span>x<span style=color:#f92672>/</span>np<span style=color:#f92672>.</span>sum(res<span style=color:#f92672>.</span>x))
</span></span><span style=display:flex><span>print(res)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> scipy<span style=color:#f92672>.</span>optimize<span style=color:#f92672>.</span>minimize(
</span></span><span style=display:flex><span>  gibbs, n0[:<span style=color:#ae81ff>4</span>], constraints<span style=color:#f92672>=</span>cons)
</span></span><span style=display:flex><span>print(
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Minimize (constained) numerical derivates:&#34;</span>,
</span></span><span style=display:flex><span>  res<span style=color:#f92672>.</span>x<span style=color:#f92672>/</span>np<span style=color:#f92672>.</span>sum(res<span style=color:#f92672>.</span>x))
</span></span><span style=display:flex><span>print(res)
</span></span></code></pre></div><p>This is way overkill for this problem, we can also solve it analytically using
the &lsquo;reaction extent&rsquo; method, and we get the same answer. In general
minimizing the Gibbs Free Energy is more flexible, and can be used to solve
much more complex problems.</p><p>So that&rsquo;s a quick overview of some common numerical methods that can be used for
optimization problems involving functions of more than one variable, or for
solving systems of nonlinear equations.</p></section><footer><nav class="p-pagination c-pagination"><div class=c-pagination__ctrl><div class=c-pagination__newer><a href=https://heathhenley.dev/posts/implementing-similar-apps-with-dissimilar-stacks/>Newer</a></div><div class=c-pagination__older><a href=https://heathhenley.dev/posts/hacking-on-s63/>Older</a></div></div></nav><section class=p-related><h3></h3><div class=p-related__list><div class="swiper swiper-container"><ul class=swiper-wrapper><li class="p-related__item swiper-slide"><a href=/posts/newton-fractals-are-cool/><span>Newton Fractals Are Cool! And a Quick Intro to Newton's Method</span></a></li><li class="p-related__item swiper-slide"><a href=/posts/memoization-in-the-wild/><span>Memoization in the Wild</span></a></li><li class="p-related__item swiper-slide"><a href=/posts/hacking-on-s63/><span>Notes: 'Hacking' on S63</span></a></li><li class="p-related__item swiper-slide"><a href=/posts/how-does-s63-enc-format-work/><span>How Does S-63 Electronic Navigational Chart (ENC) Format Work?</span></a></li><li class="p-related__item swiper-slide"><a href=/posts/add-callout-captions-to-camtasia-2023/><span>Add Callout Captions to Camtasia 2023</span></a></li><li class="p-related__item swiper-slide"><a href=/posts/python-random-module-random-notes/><span>Random Notes About Python's Random Module</span></a></li></ul></div><div class=related-prev></div><div class=related-next></div></div></section><aside class=p-author><div class="c-avatar p-author__avatar"><img alt="Author Avatar" src=/heathcropped.png></div><div class=p-author__body><p class="c-title p-author__name">Heath Henley</p><p>Chemical Engineer turned Software Engineer writing about development, numerical methods, travel, and whatever else comes up that seems worth sharing</p><p><a href=mailto:heath.j.henley@gmail.com>Contact me</a></p></div></aside></footer></article></main><nav class="l-nav p-menu"><ul class=p-menu__lists><li class=p-menu__listitem><a href=/>Blog</a></li><li class=p-menu__listitem><a href=/about>About</a></li><li class=p-menu__listitem><a href=/tutoring>Tutoring</a></li><li class=p-menu__listitem><a href=/writing>Writing</a></li></ul></nav><footer class=l-footer><ul class=c-links><li class=c-links__item><a href=https://bsky.app/profile/heathhenley.dev target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title/><use xlink:href="#icon-bluesky"/></svg></a></li><li class=c-links__item><a href=https://twitter.com/Heath_Henley target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>twitter</title><use xlink:href="#icon-twitter"/></svg></a></li><li class=c-links__item><a href=https://instagram.com/keith_with_an_h target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>instagram</title><use xlink:href="#icon-instagram"/></svg></a></li><li class=c-links__item><a href=https://github.com/heathhenley target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>github</title><use xlink:href="#icon-github"/></svg></a></li><li class=c-links__item><a href=https://linkedin.com/in/hhenley target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>linkedin</title><use xlink:href="#icon-linkedin"/></svg></a></li></ul><p class=p-copyright>Heath Henley
&nbsp;&bull;&nbsp;
2025
&nbsp;&bull;&nbsp;
<a href=https://heathhenley.dev/>Blogging by Heath™</a></p></footer><script type=text/javascript src=https://heathhenley.dev/js/bundle.js defer></script></body></html>